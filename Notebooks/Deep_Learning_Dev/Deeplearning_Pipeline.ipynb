{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0b29b8bf-a73e-4803-9641-60343bf4afa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl  \n",
    "import pandas as pd\n",
    "import numpy as np  \n",
    "from sklearn.model_selection import train_test_split  \n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from datetime import datetime, timedelta\n",
    "import random\n",
    "import onnx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "03623485-1986-49e6-9c04-c0bad591c3b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(num_records=100):\n",
    "    stock_symbols = [\"AAPL\", \"GOOG\", \"MSFT\", \"AMZN\", \"TSLA\", \"NFLX\"]\n",
    "    base_date = datetime(2024, 11, 19, 12, 0, 0)\n",
    "    \n",
    "    records = []\n",
    "    for _ in range(num_records):\n",
    "        stock_symbol = random.choice(stock_symbols)\n",
    "        current_price = round(random.uniform(100, 3000), 2)\n",
    "        change = round(random.uniform(-10, 10), 2)\n",
    "        previous_close_price = current_price - change\n",
    "        percent_change = round((change / previous_close_price) * 100, 2) if previous_close_price else 0\n",
    "        high_price_of_the_day = round(current_price + random.uniform(0, 20), 2)\n",
    "        low_price_of_the_day = round(current_price - random.uniform(0, 20), 2)\n",
    "        open_price_of_the_day = round(previous_close_price + random.uniform(-5, 5), 2)\n",
    "        record_datetime = base_date + timedelta(minutes=random.randint(0, 1440))\n",
    "        \n",
    "        records.append({\n",
    "            \"stock_symbol\": stock_symbol,\n",
    "            \"current_price\": current_price,\n",
    "            \"change\": change,\n",
    "            \"percent_change\": percent_change,\n",
    "            \"high_price_of_the_day\": high_price_of_the_day,\n",
    "            \"low_price_of_the_day\": low_price_of_the_day,\n",
    "            \"open_price_of_the_day\": open_price_of_the_day,\n",
    "            \"previous_close_price\": previous_close_price,\n",
    "            \"Datetime\": record_datetime.strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "            \"Date\": record_datetime.strftime(\"%Y-%m-%d\"),\n",
    "            \"Day\": record_datetime.day,\n",
    "            \"Month\": record_datetime.month,\n",
    "            \"Year\": record_datetime.year,\n",
    "            \"Hour\": record_datetime.hour,\n",
    "            \"Min\": record_datetime.minute,\n",
    "            \"Sec\": record_datetime.second,\n",
    "        })\n",
    "\n",
    "    return pl.DataFrame(records)\n",
    "silver_stock_prices_fact = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "370c0def-3631-4c0a-a3d5-3548a096c351",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(data):\n",
    "        df = data.with_columns([\n",
    "            (pl.col(\"Datetime\").str.strptime(pl.Datetime)).alias(\"Datetime\")\n",
    "        ])\n",
    "        numeric_cols = [\"current_price\", \"change\", \"percent_change\", \"high_price_of_the_day\",\n",
    "                        \"low_price_of_the_day\", \"open_price_of_the_day\", \"previous_close_price\"]\n",
    "        df = df.select(numeric_cols)\n",
    "        # Scaling\n",
    "        scaler = MinMaxScaler()\n",
    "        df_scaled = scaler.fit_transform(df.to_pandas())\n",
    "        return df_scaled\n",
    "\n",
    "data_scaled = preprocess_data(silver_stock_prices_fact)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f8f308a3-736d-4c4c-aee8-f5bffed102a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sequences(data, sequence_length=60):\n",
    "    X, y = [], []\n",
    "    for i in range(len(data) - sequence_length):\n",
    "        X.append(data[i:i + sequence_length])\n",
    "        y.append(data[i + sequence_length, 0])  # Predicting the current_price\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "X, y = create_sequences(data_scaled)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9744e67a-4a6e-420c-b677-722bc6b8fee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, output_size):\n",
    "        super().__init__()\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        lstm_out, _ = self.lstm(x)\n",
    "        # Take the last output of LSTM\n",
    "        lstm_out = lstm_out[:, -1, :]\n",
    "        return self.fc(lstm_out)\n",
    "\n",
    "def build_model( input_size, hidden_size=64, num_layers=2, output_size=1):\n",
    "    model = LSTMModel(input_size, hidden_size, num_layers, output_size).to(device)\n",
    "    return model\n",
    "\n",
    "model= build_model(input_size=X_train.shape[2]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aa1f2162-6926-493b-af04-6274b1e1954c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Loss: 0.28703856468200684, Val Loss: 0.2916637063026428\n",
      "Epoch 2/10, Loss: 0.2560417652130127, Val Loss: 0.25490081310272217\n",
      "Epoch 3/10, Loss: 0.22717790305614471, Val Loss: 0.21970653533935547\n",
      "Epoch 4/10, Loss: 0.20021559298038483, Val Loss: 0.1858130693435669\n",
      "Epoch 5/10, Loss: 0.17506296932697296, Val Loss: 0.15315622091293335\n",
      "Epoch 6/10, Loss: 0.15186472237110138, Val Loss: 0.12200917303562164\n",
      "Epoch 7/10, Loss: 0.13113407790660858, Val Loss: 0.09315484762191772\n",
      "Epoch 8/10, Loss: 0.11392109841108322, Val Loss: 0.06816042959690094\n",
      "Epoch 9/10, Loss: 0.10203973948955536, Val Loss: 0.049699608236551285\n",
      "Epoch 10/10, Loss: 0.0981411337852478, Val Loss: 0.041005317121744156\n"
     ]
    }
   ],
   "source": [
    "def train_model(model, X_train, y_train, X_val, y_val, epochs=10, batch_size=32, learning_rate=0.001):\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    X_train_tensor = torch.tensor(X_train, dtype=torch.float32).to(device)\n",
    "    y_train_tensor = torch.tensor(y_train, dtype=torch.float32).to(device)\n",
    "    X_val_tensor = torch.tensor(X_val, dtype=torch.float32).to(device)\n",
    "    y_val_tensor = torch.tensor(y_val, dtype=torch.float32).to(device)\n",
    "\n",
    "    train_dataset = torch.utils.data.TensorDataset(X_train_tensor, y_train_tensor)\n",
    "    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        for batch_X, batch_y in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(batch_X)\n",
    "            loss = criterion(outputs, batch_y.unsqueeze(1))\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            val_outputs = model(X_val_tensor)\n",
    "            val_loss = criterion(val_outputs, y_val_tensor.unsqueeze(1))\n",
    "        print(f\"Epoch {epoch + 1}/{epochs}, Loss: {loss.item()}, Val Loss: {val_loss.item()}\")\n",
    "    return model\n",
    "\n",
    "model_ = train_model(model, X_train, y_train, X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9bcc5453-6df4-492e-9818-b496acb565e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved as model.onnx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\NolanM\\Desktop\\Seminar\\venv\\lib\\site-packages\\torch\\onnx\\symbolic_opset9.py:4279: UserWarning: Exporting a model to ONNX with a batch_size other than 1, with a variable length with LSTM can cause an error when running the ONNX model with a different batch size. Make sure to save the model with a batch size of 1, or define the initial states (h0/c0) as inputs of the model. \n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "def save_model_to_onnx(model_, filepath=\"model.onnx\", input_size=7, sequence_length=60):\n",
    "        dummy_input = torch.randn(1, sequence_length, input_size).to(device)\n",
    "        torch.onnx.export(model_, dummy_input, filepath, export_params=True, opset_version=11)\n",
    "        print(f\"Model saved as {filepath}\")\n",
    "    \n",
    "save_model_to_onnx(model_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49083bda-fca7-4f09-98bd-8ec5a77e5991",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Loss: 0.36935168504714966, Val Loss: 0.3595671057701111\n",
      "Epoch 2/10, Loss: 0.33783218264579773, Val Loss: 0.32574552297592163\n",
      "Epoch 3/10, Loss: 0.30832916498184204, Val Loss: 0.2930193543434143\n",
      "Epoch 4/10, Loss: 0.28015708923339844, Val Loss: 0.26085108518600464\n",
      "Epoch 5/10, Loss: 0.2529056668281555, Val Loss: 0.22890505194664001\n",
      "Epoch 6/10, Loss: 0.22636990249156952, Val Loss: 0.19697800278663635\n",
      "Epoch 7/10, Loss: 0.20050835609436035, Val Loss: 0.1650407761335373\n",
      "Epoch 8/10, Loss: 0.17550356686115265, Val Loss: 0.13335151970386505\n",
      "Epoch 9/10, Loss: 0.15189111232757568, Val Loss: 0.10265946388244629\n",
      "Epoch 10/10, Loss: 0.13077639043331146, Val Loss: 0.07456889003515244\n",
      "Model saved as model.onnx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\NolanM\\Desktop\\Seminar\\venv\\lib\\site-packages\\torch\\onnx\\symbolic_opset9.py:4279: UserWarning: Exporting a model to ONNX with a batch_size other than 1, with a variable length with LSTM can cause an error when running the ONNX model with a different batch size. Make sure to save the model with a batch size of 1, or define the initial states (h0/c0) as inputs of the model. \n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "class StockPricePredictionModel:\n",
    "    def __init__(self):\n",
    "        self.scaler = None\n",
    "        self.model = None\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    def load_data(self, num_records=100):\n",
    "        stock_symbols = [\"AAPL\", \"GOOG\", \"MSFT\", \"AMZN\", \"TSLA\", \"NFLX\"]\n",
    "        base_date = datetime(2024, 11, 19, 12, 0, 0)\n",
    "        \n",
    "        records = []\n",
    "        for _ in range(num_records):\n",
    "            stock_symbol = random.choice(stock_symbols)\n",
    "            current_price = round(random.uniform(100, 3000), 2)\n",
    "            change = round(random.uniform(-10, 10), 2)\n",
    "            previous_close_price = current_price - change\n",
    "            percent_change = round((change / previous_close_price) * 100, 2) if previous_close_price else 0\n",
    "            high_price_of_the_day = round(current_price + random.uniform(0, 20), 2)\n",
    "            low_price_of_the_day = round(current_price - random.uniform(0, 20), 2)\n",
    "            open_price_of_the_day = round(previous_close_price + random.uniform(-5, 5), 2)\n",
    "            record_datetime = base_date + timedelta(minutes=random.randint(0, 1440))\n",
    "            \n",
    "            records.append({\n",
    "                \"stock_symbol\": stock_symbol,\n",
    "                \"current_price\": current_price,\n",
    "                \"change\": change,\n",
    "                \"percent_change\": percent_change,\n",
    "                \"high_price_of_the_day\": high_price_of_the_day,\n",
    "                \"low_price_of_the_day\": low_price_of_the_day,\n",
    "                \"open_price_of_the_day\": open_price_of_the_day,\n",
    "                \"previous_close_price\": previous_close_price,\n",
    "                \"Datetime\": record_datetime.strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "                \"Date\": record_datetime.strftime(\"%Y-%m-%d\"),\n",
    "                \"Day\": record_datetime.day,\n",
    "                \"Month\": record_datetime.month,\n",
    "                \"Year\": record_datetime.year,\n",
    "                \"Hour\": record_datetime.hour,\n",
    "                \"Min\": record_datetime.minute,\n",
    "                \"Sec\": record_datetime.second,\n",
    "            })\n",
    "        self.silver_stock_prices_fact = pl.DataFrame(records)\n",
    "        return self.silver_stock_prices_fact\n",
    "\n",
    "    def preprocess_data(self):\n",
    "        df = self.silver_stock_prices_fact.with_columns([\n",
    "            (pl.col(\"Datetime\").str.strptime(pl.Datetime)).alias(\"Datetime\")\n",
    "        ])\n",
    "        numeric_cols = [\"current_price\", \"change\", \"percent_change\", \"high_price_of_the_day\",\n",
    "                        \"low_price_of_the_day\", \"open_price_of_the_day\", \"previous_close_price\"]\n",
    "        df = df.select(numeric_cols)\n",
    "        # Scaling\n",
    "        self.scaler = MinMaxScaler()\n",
    "        df_scaled = self.scaler.fit_transform(df.to_pandas())\n",
    "        return df_scaled\n",
    "\n",
    "    def create_sequences(self, data, sequence_length=60):\n",
    "        X, y = [], []\n",
    "        for i in range(len(data) - sequence_length):\n",
    "            X.append(data[i:i + sequence_length])\n",
    "            y.append(data[i + sequence_length, 0])  # Predicting the current_price\n",
    "        return np.array(X), np.array(y)\n",
    "\n",
    "    class LSTMModel(nn.Module):\n",
    "        def __init__(self, input_size, hidden_size, num_layers, output_size):\n",
    "            super().__init__()\n",
    "            self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "            self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "        def forward(self, x):\n",
    "            lstm_out, _ = self.lstm(x)\n",
    "            # Take the last output of LSTM\n",
    "            lstm_out = lstm_out[:, -1, :]\n",
    "            return self.fc(lstm_out)\n",
    "\n",
    "    def build_model(self, input_size, hidden_size=64, num_layers=2, output_size=1):\n",
    "        self.model = self.LSTMModel(input_size, hidden_size, num_layers, output_size).to(self.device)\n",
    "\n",
    "    def train_model(self, X_train, y_train, X_val, y_val, epochs=10, batch_size=32, learning_rate=0.001):\n",
    "        criterion = nn.MSELoss()\n",
    "        optimizer = optim.Adam(self.model.parameters(), lr=learning_rate)\n",
    "\n",
    "        X_train_tensor = torch.tensor(X_train, dtype=torch.float32).to(self.device)\n",
    "        y_train_tensor = torch.tensor(y_train, dtype=torch.float32).to(self.device)\n",
    "        X_val_tensor = torch.tensor(X_val, dtype=torch.float32).to(self.device)\n",
    "        y_val_tensor = torch.tensor(y_val, dtype=torch.float32).to(self.device)\n",
    "\n",
    "        train_dataset = torch.utils.data.TensorDataset(X_train_tensor, y_train_tensor)\n",
    "        train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "            self.model.train()\n",
    "            for batch_X, batch_y in train_loader:\n",
    "                optimizer.zero_grad()\n",
    "                outputs = self.model(batch_X)\n",
    "                loss = criterion(outputs, batch_y.unsqueeze(1))\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "            self.model.eval()\n",
    "            with torch.no_grad():\n",
    "                val_outputs = self.model(X_val_tensor)\n",
    "                val_loss = criterion(val_outputs, y_val_tensor.unsqueeze(1))\n",
    "            print(f\"Epoch {epoch + 1}/{epochs}, Loss: {loss.item()}, Val Loss: {val_loss.item()}\")\n",
    "\n",
    "    def save_model_to_onnx(self, filepath=\"model.onnx\", input_size=7, sequence_length=60):\n",
    "        dummy_input = torch.randn(1, sequence_length, input_size).to(self.device)\n",
    "        torch.onnx.export(self.model, dummy_input, filepath, export_params=True, opset_version=11)\n",
    "        print(f\"Model saved as {filepath}\")\n",
    "\n",
    "    def process(self):\n",
    "        self.load_data()\n",
    "        data_scaled = self.preprocess_data()\n",
    "\n",
    "        X, y = self.create_sequences(data_scaled)\n",
    "        X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "        self.build_model(input_size=X_train.shape[2])\n",
    "        self.train_model(X_train, y_train, X_val, y_val)\n",
    "        self.save_model_to_onnx()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    stock_model = StockPricePredictionModel()\n",
    "    stock_model.process()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
